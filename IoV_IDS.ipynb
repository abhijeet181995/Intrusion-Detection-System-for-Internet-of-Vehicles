{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IoV_IDS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq-SbHCIpQfK"
      },
      "source": [
        "# DATASET PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP3JgAY7LvJD",
        "outputId": "92c155b8-0b80-4185-d5c7-d494ffda8cbb"
      },
      "source": [
        "# !gdown --id 0Bx1Nsg-bc9ovNGRlVGJteGhGZ3c\n",
        "!gdown --id 1gq7Fq-bVHW8k0V_N08QShWTH9W9AC_7B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gq7Fq-bVHW8k0V_N08QShWTH9W9AC_7B\n",
            "To: /content/CICIDS2017_sample.csv\n",
            "100% 19.9M/19.9M [00:00<00:00, 63.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDMU45H87Quh",
        "outputId": "ac19e9c7-3cf9-4028-e510-2b876a033536"
      },
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Q3Ql5bU0Qt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "from imblearn.over_sampling import ADASYN "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WdZe_TVU8WT"
      },
      "source": [
        "df = pd.read_csv('./CICIDS2017_sample.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "AdzgaPyCoVQp",
        "outputId": "19dd8e08-7dd2-4d4e-c5ad-721e610966ab"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Bwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Bwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Fwd Header Length.1</th>\n",
              "      <th>Fwd Avg Bytes/Bulk</th>\n",
              "      <th>Fwd Avg Packets/Bulk</th>\n",
              "      <th>Fwd Avg Bulk Rate</th>\n",
              "      <th>Bwd Avg Bytes/Bulk</th>\n",
              "      <th>Bwd Avg Packets/Bulk</th>\n",
              "      <th>Bwd Avg Bulk Rate</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.0</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>56580.000000</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "      <td>5.658000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.943518e+07</td>\n",
              "      <td>5.899346</td>\n",
              "      <td>5.448533</td>\n",
              "      <td>7.335495e+02</td>\n",
              "      <td>5.289977e+03</td>\n",
              "      <td>166.603393</td>\n",
              "      <td>10.118540</td>\n",
              "      <td>43.213831</td>\n",
              "      <td>57.414468</td>\n",
              "      <td>1554.830134</td>\n",
              "      <td>21.494910</td>\n",
              "      <td>508.463045</td>\n",
              "      <td>644.854237</td>\n",
              "      <td>9.277010e+05</td>\n",
              "      <td>7.784788e+04</td>\n",
              "      <td>1.845205e+06</td>\n",
              "      <td>4.863215e+06</td>\n",
              "      <td>1.603282e+07</td>\n",
              "      <td>1.822564e+05</td>\n",
              "      <td>1.914268e+07</td>\n",
              "      <td>3.514447e+06</td>\n",
              "      <td>6.340282e+06</td>\n",
              "      <td>1.592662e+07</td>\n",
              "      <td>6.538754e+05</td>\n",
              "      <td>8.682916e+06</td>\n",
              "      <td>1.595563e+06</td>\n",
              "      <td>2.162991e+06</td>\n",
              "      <td>5.720259e+06</td>\n",
              "      <td>5.393139e+05</td>\n",
              "      <td>0.038530</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>160.228420</td>\n",
              "      <td>145.955567</td>\n",
              "      <td>6.959740e+04</td>\n",
              "      <td>8.250477e+03</td>\n",
              "      <td>8.722322</td>\n",
              "      <td>1607.301997</td>\n",
              "      <td>256.386444</td>\n",
              "      <td>505.203292</td>\n",
              "      <td>1.036491e+06</td>\n",
              "      <td>0.059014</td>\n",
              "      <td>0.038530</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.400141</td>\n",
              "      <td>0.364669</td>\n",
              "      <td>0.073224</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.633510</td>\n",
              "      <td>282.819684</td>\n",
              "      <td>43.213831</td>\n",
              "      <td>508.463045</td>\n",
              "      <td>160.228420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.899346</td>\n",
              "      <td>7.335495e+02</td>\n",
              "      <td>5.448533</td>\n",
              "      <td>5.289372e+03</td>\n",
              "      <td>8047.932131</td>\n",
              "      <td>2003.000336</td>\n",
              "      <td>3.120237</td>\n",
              "      <td>26.952633</td>\n",
              "      <td>8.139353e+04</td>\n",
              "      <td>2.736039e+04</td>\n",
              "      <td>1.209187e+05</td>\n",
              "      <td>6.493503e+04</td>\n",
              "      <td>1.476543e+07</td>\n",
              "      <td>8.700597e+05</td>\n",
              "      <td>1.542144e+07</td>\n",
              "      <td>1.412669e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.674270e+07</td>\n",
              "      <td>56.939175</td>\n",
              "      <td>66.560471</td>\n",
              "      <td>2.136734e+04</td>\n",
              "      <td>1.093474e+05</td>\n",
              "      <td>669.516266</td>\n",
              "      <td>47.889018</td>\n",
              "      <td>174.204630</td>\n",
              "      <td>224.898191</td>\n",
              "      <td>2775.271519</td>\n",
              "      <td>53.472078</td>\n",
              "      <td>848.403748</td>\n",
              "      <td>1219.682770</td>\n",
              "      <td>2.110127e+07</td>\n",
              "      <td>2.702542e+05</td>\n",
              "      <td>4.805157e+06</td>\n",
              "      <td>9.928740e+06</td>\n",
              "      <td>3.289800e+07</td>\n",
              "      <td>3.313042e+06</td>\n",
              "      <td>3.673218e+07</td>\n",
              "      <td>8.946897e+06</td>\n",
              "      <td>1.352426e+07</td>\n",
              "      <td>3.295312e+07</td>\n",
              "      <td>6.901865e+06</td>\n",
              "      <td>2.659211e+07</td>\n",
              "      <td>7.367544e+06</td>\n",
              "      <td>8.436279e+06</td>\n",
              "      <td>2.069353e+07</td>\n",
              "      <td>6.128549e+06</td>\n",
              "      <td>0.192472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1218.200185</td>\n",
              "      <td>1357.412561</td>\n",
              "      <td>2.636960e+05</td>\n",
              "      <td>3.978154e+04</td>\n",
              "      <td>19.763447</td>\n",
              "      <td>2819.655139</td>\n",
              "      <td>407.863706</td>\n",
              "      <td>883.941012</td>\n",
              "      <td>2.402070e+06</td>\n",
              "      <td>0.235653</td>\n",
              "      <td>0.192472</td>\n",
              "      <td>0.011890</td>\n",
              "      <td>0.489931</td>\n",
              "      <td>0.481342</td>\n",
              "      <td>0.260506</td>\n",
              "      <td>0.004204</td>\n",
              "      <td>0.011890</td>\n",
              "      <td>0.626346</td>\n",
              "      <td>447.600416</td>\n",
              "      <td>174.204630</td>\n",
              "      <td>848.403748</td>\n",
              "      <td>1218.200185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.939175</td>\n",
              "      <td>2.136734e+04</td>\n",
              "      <td>66.560471</td>\n",
              "      <td>1.092285e+05</td>\n",
              "      <td>13385.862148</td>\n",
              "      <td>7775.325260</td>\n",
              "      <td>53.274003</td>\n",
              "      <td>6.798056</td>\n",
              "      <td>7.401506e+05</td>\n",
              "      <td>3.342942e+05</td>\n",
              "      <td>9.394422e+05</td>\n",
              "      <td>6.840410e+05</td>\n",
              "      <td>3.215987e+07</td>\n",
              "      <td>6.316148e+06</td>\n",
              "      <td>3.303321e+07</td>\n",
              "      <td>3.192938e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.679848e-02</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.679848e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.300000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.441602e+01</td>\n",
              "      <td>7.617586e-01</td>\n",
              "      <td>5.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.100000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>5.678805e-01</td>\n",
              "      <td>6.151467e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.944900e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.100000e+01</td>\n",
              "      <td>8.100000e+01</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.928571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.714995e+03</td>\n",
              "      <td>8.071050e+01</td>\n",
              "      <td>1.702825e+04</td>\n",
              "      <td>1.374408e+04</td>\n",
              "      <td>4.859800e+04</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>6.750000e+02</td>\n",
              "      <td>3.415000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.050000e+02</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>4.098823e+01</td>\n",
              "      <td>4.344003e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>12.776280</td>\n",
              "      <td>1.632333e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>48.571429</td>\n",
              "      <td>8.666667</td>\n",
              "      <td>29.928571</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.100000e+01</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.100000e+01</td>\n",
              "      <td>274.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.839752e+06</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.830000e+02</td>\n",
              "      <td>4.867000e+03</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>47.750000</td>\n",
              "      <td>78.686539</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>536.747222</td>\n",
              "      <td>658.616786</td>\n",
              "      <td>1.229892e+05</td>\n",
              "      <td>2.898551e+04</td>\n",
              "      <td>1.717790e+06</td>\n",
              "      <td>3.029123e+06</td>\n",
              "      <td>5.773170e+06</td>\n",
              "      <td>6.000000e+01</td>\n",
              "      <td>6.298666e+06</td>\n",
              "      <td>2.429947e+06</td>\n",
              "      <td>3.467893e+06</td>\n",
              "      <td>5.683576e+06</td>\n",
              "      <td>6.700000e+01</td>\n",
              "      <td>1.498912e+05</td>\n",
              "      <td>3.383725e+04</td>\n",
              "      <td>5.598279e+04</td>\n",
              "      <td>1.360388e+05</td>\n",
              "      <td>4.500000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>1.486996e+04</td>\n",
              "      <td>9.132420e+03</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1689.000000</td>\n",
              "      <td>318.307692</td>\n",
              "      <td>563.655320</td>\n",
              "      <td>3.177073e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>338.186364</td>\n",
              "      <td>47.750000</td>\n",
              "      <td>536.747222</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.830000e+02</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.867000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>6930.000000</td>\n",
              "      <td>9877.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>2.150000e+07</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>1983.000000</td>\n",
              "      <td>5940.857143</td>\n",
              "      <td>7049.469004</td>\n",
              "      <td>11632.000000</td>\n",
              "      <td>1448.000000</td>\n",
              "      <td>3869.000000</td>\n",
              "      <td>6694.376371</td>\n",
              "      <td>2.070000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>8.190000e+07</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>8.340000e+07</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>7.780000e+07</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>152936.000000</td>\n",
              "      <td>197552.000000</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1326.000000</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>2064.551724</td>\n",
              "      <td>4708.990311</td>\n",
              "      <td>2.220000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2138.285714</td>\n",
              "      <td>5940.857143</td>\n",
              "      <td>3869.000000</td>\n",
              "      <td>152936.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6930.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>9877.000000</td>\n",
              "      <td>2.146579e+07</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>5994.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>2.610000e+07</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>6.860000e+07</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Flow Duration  Total Fwd Packets  ...      Idle Max      Idle Min\n",
              "count   5.658000e+04       56580.000000  ...  5.658000e+04  5.658000e+04\n",
              "mean    1.943518e+07           5.899346  ...  1.542144e+07  1.412669e+07\n",
              "std     3.674270e+07          56.939175  ...  3.303321e+07  3.192938e+07\n",
              "min     1.000000e+00           1.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%     7.300000e+01           1.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%     5.944900e+04           2.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%     8.839752e+06           5.000000  ...  0.000000e+00  0.000000e+00\n",
              "max     1.200000e+08        6930.000000  ...  1.190000e+08  1.190000e+08\n",
              "\n",
              "[8 rows x 77 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3uILiGapM7v",
        "outputId": "e6ba55f4-eabd-4499-fe29-980190db85b0"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56580 entries, 0 to 56660\n",
            "Data columns (total 78 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Flow Duration                56580 non-null  int64  \n",
            " 1   Total Fwd Packets            56580 non-null  int64  \n",
            " 2   Total Backward Packets       56580 non-null  int64  \n",
            " 3   Total Length of Fwd Packets  56580 non-null  int64  \n",
            " 4   Total Length of Bwd Packets  56580 non-null  int64  \n",
            " 5   Fwd Packet Length Max        56580 non-null  int64  \n",
            " 6   Fwd Packet Length Min        56580 non-null  int64  \n",
            " 7   Fwd Packet Length Mean       56580 non-null  float64\n",
            " 8   Fwd Packet Length Std        56580 non-null  float64\n",
            " 9   Bwd Packet Length Max        56580 non-null  int64  \n",
            " 10  Bwd Packet Length Min        56580 non-null  int64  \n",
            " 11  Bwd Packet Length Mean       56580 non-null  float64\n",
            " 12  Bwd Packet Length Std        56580 non-null  float64\n",
            " 13  Flow Bytes/s                 56580 non-null  float64\n",
            " 14  Flow Packets/s               56580 non-null  float64\n",
            " 15  Flow IAT Mean                56580 non-null  float64\n",
            " 16  Flow IAT Std                 56580 non-null  float64\n",
            " 17  Flow IAT Max                 56580 non-null  int64  \n",
            " 18  Flow IAT Min                 56580 non-null  int64  \n",
            " 19  Fwd IAT Total                56580 non-null  int64  \n",
            " 20  Fwd IAT Mean                 56580 non-null  float64\n",
            " 21  Fwd IAT Std                  56580 non-null  float64\n",
            " 22  Fwd IAT Max                  56580 non-null  int64  \n",
            " 23  Fwd IAT Min                  56580 non-null  int64  \n",
            " 24  Bwd IAT Total                56580 non-null  int64  \n",
            " 25  Bwd IAT Mean                 56580 non-null  float64\n",
            " 26  Bwd IAT Std                  56580 non-null  float64\n",
            " 27  Bwd IAT Max                  56580 non-null  int64  \n",
            " 28  Bwd IAT Min                  56580 non-null  int64  \n",
            " 29  Fwd PSH Flags                56580 non-null  int64  \n",
            " 30  Bwd PSH Flags                56580 non-null  int64  \n",
            " 31  Fwd URG Flags                56580 non-null  int64  \n",
            " 32  Bwd URG Flags                56580 non-null  int64  \n",
            " 33  Fwd Header Length            56580 non-null  int64  \n",
            " 34  Bwd Header Length            56580 non-null  int64  \n",
            " 35  Fwd Packets/s                56580 non-null  float64\n",
            " 36  Bwd Packets/s                56580 non-null  float64\n",
            " 37  Min Packet Length            56580 non-null  int64  \n",
            " 38  Max Packet Length            56580 non-null  int64  \n",
            " 39  Packet Length Mean           56580 non-null  float64\n",
            " 40  Packet Length Std            56580 non-null  float64\n",
            " 41  Packet Length Variance       56580 non-null  float64\n",
            " 42  FIN Flag Count               56580 non-null  int64  \n",
            " 43  SYN Flag Count               56580 non-null  int64  \n",
            " 44  RST Flag Count               56580 non-null  int64  \n",
            " 45  PSH Flag Count               56580 non-null  int64  \n",
            " 46  ACK Flag Count               56580 non-null  int64  \n",
            " 47  URG Flag Count               56580 non-null  int64  \n",
            " 48  CWE Flag Count               56580 non-null  int64  \n",
            " 49  ECE Flag Count               56580 non-null  int64  \n",
            " 50  Down/Up Ratio                56580 non-null  int64  \n",
            " 51  Average Packet Size          56580 non-null  float64\n",
            " 52  Avg Fwd Segment Size         56580 non-null  float64\n",
            " 53  Avg Bwd Segment Size         56580 non-null  float64\n",
            " 54  Fwd Header Length.1          56580 non-null  int64  \n",
            " 55  Fwd Avg Bytes/Bulk           56580 non-null  int64  \n",
            " 56  Fwd Avg Packets/Bulk         56580 non-null  int64  \n",
            " 57  Fwd Avg Bulk Rate            56580 non-null  int64  \n",
            " 58  Bwd Avg Bytes/Bulk           56580 non-null  int64  \n",
            " 59  Bwd Avg Packets/Bulk         56580 non-null  int64  \n",
            " 60  Bwd Avg Bulk Rate            56580 non-null  int64  \n",
            " 61  Subflow Fwd Packets          56580 non-null  int64  \n",
            " 62  Subflow Fwd Bytes            56580 non-null  int64  \n",
            " 63  Subflow Bwd Packets          56580 non-null  int64  \n",
            " 64  Subflow Bwd Bytes            56580 non-null  int64  \n",
            " 65  Init_Win_bytes_forward       56580 non-null  int64  \n",
            " 66  Init_Win_bytes_backward      56580 non-null  int64  \n",
            " 67  act_data_pkt_fwd             56580 non-null  int64  \n",
            " 68  min_seg_size_forward         56580 non-null  int64  \n",
            " 69  Active Mean                  56580 non-null  float64\n",
            " 70  Active Std                   56580 non-null  float64\n",
            " 71  Active Max                   56580 non-null  int64  \n",
            " 72  Active Min                   56580 non-null  int64  \n",
            " 73  Idle Mean                    56580 non-null  float64\n",
            " 74  Idle Std                     56580 non-null  float64\n",
            " 75  Idle Max                     56580 non-null  int64  \n",
            " 76  Idle Min                     56580 non-null  int64  \n",
            " 77  Label                        56580 non-null  object \n",
            "dtypes: float64(24), int64(53), object(1)\n",
            "memory usage: 34.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl22xwxqNBZm"
      },
      "source": [
        "# x = x.apply(pd.to_numeric, errors='coerce')\n",
        "# x=pd.DataFrame(scaler.fit_transform(x),columns = x.columns)\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU8sDSAPgQtE"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "y= df['Label']\n",
        "x = df.drop('Label', 1)\n",
        "x=pd.DataFrame(scaler.fit_transform(x),columns = x.columns)\n",
        "le = LabelEncoder()\n",
        "y=le.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YKwjgSON5d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138a1fea-b20a-4a24-e051-691340cfe977"
      },
      "source": [
        "print(np.unique(y,return_counts=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1, 2, 3, 4, 5, 6]), array([22719,  1956,  2767, 18984,    36,  7938,  2180]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjzCrlbCgUle"
      },
      "source": [
        "# labelencoder = LabelEncoder()\n",
        "# df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
        "# X = df.drop(['Label'],axis=1).values \n",
        "# y = df.iloc[:, -1].values.reshape(-1,1)\n",
        "# y=np.ravel(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
        "# X_train, X_validate, y_train, y_validate = train_test_split(X_train,y_train,  train_size = 0.8, test_size = 0.2 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjGSDpyHgfpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1b3a96-4d1a-4222-c9fc-286f3ef2b6b1"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "# print(X_validate.shape)\n",
        "# print(y_validate.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45264, 77)\n",
            "(11316, 77)\n",
            "(45264,)\n",
            "(11316,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8qOEJ9CDydO"
      },
      "source": [
        "### Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6IVcKH9goJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2036f34f-300f-4415-dc84-533d42c95108"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_train, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6]),\n",
              " array([18274,  1555,  2201, 15095,    28,  6353,  1758]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uz6GeQD7hvl",
        "outputId": "7304cca5-a6cb-4f39-ce57-ad9c99cb0eab"
      },
      "source": [
        "sm = ADASYN()\n",
        "X_train_r, y_train_r = sm.fit_resample(X_train, y_train)\n",
        "print(X_train_r.shape)\n",
        "print(y_train_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127823, 77)\n",
            "(127823,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7sB67Cg4sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91adf8e-fd6e-4bd2-ee73-4d43fd728a82"
      },
      "source": [
        "np.unique(y_train_r, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6]),\n",
              " array([18274, 18222, 18261, 18251, 18271, 18260, 18284]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MpdtdoQDrG6"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4E8Qo-_uyvV"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "xgb_cl = xgb.XGBClassifier()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100)\n",
        "lgm_clf= LGBMClassifier()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('xg',xgb_cl), ('rnf', rnd_clf), ('abd', lgm_clf)],\n",
        "    voting='soft',weights=[1,1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b34IukD7u0iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81015f0a-25e2-4460-c3ec-8b0d83825d5e"
      },
      "source": [
        "rnd_clf.fit(X_train_r, y_train_r)\n",
        "y_pred = rnd_clf.predict(X_test)\n",
        "print(rnd_clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier 0.9917815482502651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMe80GNYv8eX",
        "outputId": "ac53a54d-d788-4a22-a81d-f238a1a960b4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (xgb_cl, rnd_clf, lgm_clf, voting_clf):\n",
        "    clf.fit(X_train_r, y_train_r)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print('--------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier 0.9799586426299046\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97      4445\n",
            "           1       0.83      1.00      0.91       401\n",
            "           2       0.99      1.00      0.99       566\n",
            "           3       0.99      0.99      0.99      3889\n",
            "           4       0.64      0.88      0.74         8\n",
            "           5       0.99      1.00      1.00      1585\n",
            "           6       0.75      0.99      0.86       422\n",
            "\n",
            "    accuracy                           0.97     11316\n",
            "   macro avg       0.88      0.97      0.92     11316\n",
            "weighted avg       0.98      0.97      0.97     11316\n",
            "\n",
            "--------------------\n",
            "RandomForestClassifier 0.9915164369034994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      4445\n",
            "           1       0.88      1.00      0.93       401\n",
            "           2       0.99      1.00      1.00       566\n",
            "           3       1.00      1.00      1.00      3889\n",
            "           4       1.00      0.75      0.86         8\n",
            "           5       1.00      1.00      1.00      1585\n",
            "           6       0.97      0.98      0.97       422\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.98      0.96      0.96     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n",
            "--------------------\n",
            "LGBMClassifier 0.9919749593495935\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      4445\n",
            "           1       0.95      1.00      0.97       401\n",
            "           2       1.00      1.00      1.00       566\n",
            "           3       1.00      1.00      1.00      3889\n",
            "           4       1.00      0.88      0.93         8\n",
            "           5       1.00      1.00      1.00      1585\n",
            "           6       0.99      1.00      0.99       422\n",
            "\n",
            "    accuracy                           1.00     11316\n",
            "   macro avg       0.99      0.98      0.98     11316\n",
            "weighted avg       1.00      1.00      1.00     11316\n",
            "\n",
            "--------------------\n",
            "VotingClassifier 0.992079179922234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      4445\n",
            "           1       0.91      1.00      0.95       401\n",
            "           2       1.00      1.00      1.00       566\n",
            "           3       1.00      1.00      1.00      3889\n",
            "           4       1.00      0.88      0.93         8\n",
            "           5       1.00      1.00      1.00      1585\n",
            "           6       0.98      1.00      0.99       422\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.98      0.98      0.98     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ469lNgu9eS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "7b9f0ce5-b735-498b-ca4c-825ed3c4c84d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "import sklearn.preprocessing\n",
        "print('Accuracy',accuracy_score(y_test, y_pred))\n",
        "print('f1_score',f1_score(y_test,y_pred,average='micro'))\n",
        "print(classification_report(y_test,y_pred))\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "f,ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.992079179922234\n",
            "f1_score 0.992079179922234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      4543\n",
            "           1       0.87      1.00      0.93       387\n",
            "           2       1.00      1.00      1.00       543\n",
            "           3       1.00      1.00      1.00      3787\n",
            "           4       1.00      0.71      0.83         7\n",
            "           5       1.00      1.00      1.00      1607\n",
            "           6       0.99      1.00      0.99       442\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.98      0.96      0.96     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f9ndU2tXduR"
      },
      "source": [
        "**Feature Select**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE4zIqpzadCZ",
        "outputId": "3563b04f-30b8-40b8-b080-bed97b5d19ac"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "sel.fit(X_train_r, y_train_r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectFromModel(estimator=RandomForestClassifier())"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiIgtQYf50U6",
        "outputId": "e42ccffc-d8ee-4e7a-f50c-f6a48b64de59"
      },
      "source": [
        "sel.get_support()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
              "       False,  True,  True, False, False,  True, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False, False, False,\n",
              "       False, False,  True, False, False, False,  True,  True,  True,\n",
              "        True, False, False, False, False, False, False,  True,  True,\n",
              "       False, False,  True,  True,  True,  True, False, False, False,\n",
              "       False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYUbTZYz6KRS",
        "outputId": "4250a34b-52be-4ac2-815a-10424e7ebf74"
      },
      "source": [
        "selected_feat= X_train_r.columns[(sel.get_support())]\n",
        "len(selected_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLshxKPc6S6c",
        "outputId": "564aee32-1ede-4085-9d7c-d61fce1162c7"
      },
      "source": [
        "print(selected_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Total Fwd Packets', 'Total Length of Fwd Packets',\n",
            "       'Total Length of Bwd Packets', 'Fwd Packet Length Max',\n",
            "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
            "       'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Flow Packets/s',\n",
            "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
            "       'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length',\n",
            "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
            "       'URG Flag Count', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
            "       'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets',\n",
            "       'Subflow Fwd Bytes', 'Init_Win_bytes_forward',\n",
            "       'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-ANp4QhKTxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEulH-LB-gOg"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'xgb_cl__criterion': ['gini', 'entropy'],\n",
        "      'svm__C': [2,3,4],}\n",
        "xgb_cl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnIF27wm6YNf"
      },
      "source": [
        "X_train_r_fr=X_train_r[selected_feat]\n",
        "X_test_fr=X_test[selected_feat]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHq67QRn8Nm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc05585-5db7-4fe9-ef7e-2b971f96645e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (xgb_cl, rnd_clf, lgm_clf, voting_clf):\n",
        "    clf.fit(X_train_r_fr, y_train_r)\n",
        "    y_pred = clf.predict(X_test_fr)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print('--------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier 0.9697773064687168\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96      4543\n",
            "           1       0.79      1.00      0.88       387\n",
            "           2       1.00      1.00      1.00       543\n",
            "           3       0.99      0.99      0.99      3787\n",
            "           4       0.62      0.71      0.67         7\n",
            "           5       0.99      1.00      0.99      1607\n",
            "           6       0.75      1.00      0.85       442\n",
            "\n",
            "    accuracy                           0.97     11316\n",
            "   macro avg       0.88      0.95      0.91     11316\n",
            "weighted avg       0.98      0.97      0.97     11316\n",
            "\n",
            "--------------------\n",
            "RandomForestClassifier 0.9944326617179216\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      4543\n",
            "           1       0.95      0.99      0.97       387\n",
            "           2       1.00      1.00      1.00       543\n",
            "           3       1.00      1.00      1.00      3787\n",
            "           4       1.00      0.71      0.83         7\n",
            "           5       1.00      1.00      1.00      1607\n",
            "           6       0.97      1.00      0.98       442\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.99      0.95      0.97     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n",
            "--------------------\n",
            "LGBMClassifier 0.9943024390243902\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      4543\n",
            "           1       0.94      1.00      0.97       387\n",
            "           2       1.00      1.00      1.00       543\n",
            "           3       1.00      1.00      1.00      3787\n",
            "           4       1.00      0.71      0.83         7\n",
            "           5       0.99      1.00      1.00      1607\n",
            "           6       0.96      1.00      0.98       442\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.99      0.96      0.97     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n",
            "--------------------\n",
            "VotingClassifier 0.9939024390243902\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      4543\n",
            "           1       0.94      0.99      0.98       387\n",
            "           2       1.00      1.00      1.00       543\n",
            "           3       1.00      1.00      1.00      3787\n",
            "           4       1.00      0.71      0.83         7\n",
            "           5       1.00      1.00      1.00      1607\n",
            "           6       0.96      1.00      0.98       442\n",
            "\n",
            "    accuracy                           0.99     11316\n",
            "   macro avg       0.98      0.96      0.97     11316\n",
            "weighted avg       0.99      0.99      0.99     11316\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vacrAXNwlFg",
        "outputId": "f88664ec-63f6-49e1-d430-0a4824898327"
      },
      "source": [
        "!pip install beautifultable\n",
        "from beautifultable import BeautifulTable\n",
        "table = BeautifulTable(maxwidth=130)\n",
        "\n",
        "table.rows.append([\"HongPo Zhnag\", \"CICIDS2017\", \"SGM\", \"multiclass\",\"RF\\nMLP\\nCNN\", \"93.08\\n99.60\\n99.85\",\" \" ,\" \", \"94.67\\n99.69\\n99.86\"])\n",
        "table.rows.append([\"Arif Yulianto et al(2019)\", \"CICIDS2017\", \"SMOTE\" ,\"binary\",\"AdaBoost\", \"81.83\",\" \" ,\" \", \"90.01\"])\n",
        "table.rows.append([\"Razab abdulhammed et al(2019)\", \"CICIDS2017\", \"UDBB\", \"multiclass\",\"RF\\nNB\\nLDA\\nQDA\", \"98.8\\n97.6\\n95.7\\n98.9\",\" \" ,\" \", \"98.8\\n97.7\\n95.7\\n99.0\"])\n",
        "table.rows.append([\"Aameer Hanif et al(2017)\", \"Customer\\nChurn\", \"UnderSampling\\nOverSampling SMOTE\" ,\"binary\",\"RF\", \"\",\" \" ,\"98.5\", \"97\"])\n",
        "table.rows.append([\"Cengiz Colak et al(2017)\", \"Atrial fibrillation\", \"SMOTE\" ,\"binary\",\"GLMBoost\\nLogitBoost\", \"82.47\\n96.65\",\" \" ,\"82.5\\n96.96\", \"\"])\n",
        "table.rows.append([\"Our work\", \"CICIDS2017\", \"ADASYN\", \"mutliclass\",\"RF\\nXgBoost\\nVotingClassifier\", \"82.47\\n96.65\",\" \" ,\"82.5\\n96.96\", \"\"])\n",
        "table.columns.header = [\"Works\", \"Dataset\", \"method\", \"Classes\", \"Classifier\",\"Acc(%)\",\"Kappa(%)\",\"AUC(%)\",\"F1(%)\"]\n",
        "table.columns.alignment = BeautifulTable.ALIGN_RIGHT\n",
        "table.set_style(BeautifulTable.STYLE_BOX_ROUNDED)\n",
        "print(table)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting beautifultable\n",
            "  Downloading beautifultable-1.0.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from beautifultable) (0.2.5)\n",
            "Installing collected packages: beautifultable\n",
            "Successfully installed beautifultable-1.0.1\n",
            "╭───────────────────────────┬─────────────────┬────────────────┬────────────┬───────────────┬────────┬──────────┬────────┬───────╮\n",
            "│                     Works │         Dataset │         method │    Classes │    Classifier │ Acc(%) │ Kappa(%) │ AUC(%) │ F1(%) │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│              HongPo Zhnag │      CICIDS2017 │            SGM │ multiclass │            RF │  93.08 │          │        │ 94.67 │\n",
            "│                           │                 │                │            │           MLP │   99.6 │          │        │ 99.69 │\n",
            "│                           │                 │                │            │           CNN │  99.85 │          │        │ 99.86 │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│ Arif Yulianto et al(2019) │      CICIDS2017 │          SMOTE │     binary │      AdaBoost │  81.83 │          │        │ 90.01 │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│ Razab abdulhammed et al(2 │      CICIDS2017 │           UDBB │ multiclass │            RF │   98.8 │          │        │  98.8 │\n",
            "│                      019) │                 │                │            │               │        │          │        │       │\n",
            "│                           │                 │                │            │            NB │   97.6 │          │        │  97.7 │\n",
            "│                           │                 │                │            │           LDA │   95.7 │          │        │  95.7 │\n",
            "│                           │                 │                │            │           QDA │   98.9 │          │        │  99.0 │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│  Aameer Hanif et al(2017) │        Customer │  UnderSampling │     binary │            RF │        │          │   98.5 │    97 │\n",
            "│                           │           Churn │ OverSampling S │            │               │        │          │        │       │\n",
            "│                           │                 │           MOTE │            │               │        │          │        │       │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│  Cengiz Colak et al(2017) │ Atrial fibrilla │          SMOTE │     binary │      GLMBoost │  82.47 │          │   82.5 │       │\n",
            "│                           │            tion │                │            │               │        │          │        │       │\n",
            "│                           │                 │                │            │    LogitBoost │  96.65 │          │  96.96 │       │\n",
            "├───────────────────────────┼─────────────────┼────────────────┼────────────┼───────────────┼────────┼──────────┼────────┼───────┤\n",
            "│                  Our work │      CICIDS2017 │         ADASYN │ mutliclass │            RF │  82.47 │          │   82.5 │       │\n",
            "│                           │                 │                │            │       XgBoost │  96.65 │          │  96.96 │       │\n",
            "│                           │                 │                │            │ VotingClassif │        │          │        │       │\n",
            "│                           │                 │                │            │           ier │        │          │        │       │\n",
            "╰───────────────────────────┴─────────────────┴────────────────┴────────────┴───────────────┴────────┴──────────┴────────┴───────╯\n"
          ]
        }
      ]
    }
  ]
}